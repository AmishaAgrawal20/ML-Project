{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter_tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OihpQT_ejBvg",
        "outputId": "bcce41a4-048f-4596-dc6d-4e37eba7d73e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV0qsDXwgsNs"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvX3hHk_VlIk"
      },
      "source": [
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from hyperopt.pyll.base import scope\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE7B8egdYClT"
      },
      "source": [
        "def printbest_model(param_space):\n",
        "    \n",
        "    hypopt_trials = Trials()\n",
        "    best_params = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=30, trials= hypopt_trials)\n",
        "    \n",
        "    print(best_params)\n",
        "    print(hypopt_trials.best_trial['result']['loss'])\n",
        "    \n",
        "    return hypopt_trials.results[np.argmin([r['loss'] for r in hypopt_trials.results])]['model']"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbdMxakiYJpS"
      },
      "source": [
        "def objective(params):\n",
        "    \n",
        "    model = RandomForestClassifier(**params, n_jobs=-1, random_state=123)\n",
        "    acc = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2-SQ2zoih7o"
      },
      "source": [
        "def get_f1_score(X_train, y_train, X_test, y_test, model):\n",
        "\n",
        "    assert X_train.shape[0] == y_train.shape[0]\n",
        "    assert X_test.shape[0] == y_test.shape[0]\n",
        "\n",
        "    X_train = Normalizer().fit_transform(X_train)\n",
        "    X_test = Normalizer().fit_transform(X_test)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    f1score = metrics.f1_score(y_test, preds, average='macro') * 100\n",
        "\n",
        "    print(f'f1-score on features: {f1score} \\n')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3JC-7lpifQV"
      },
      "source": [
        "def feature_sum(vec_list):\n",
        "    vec_list = np.array(vec_list)\n",
        "    vec_sum = vec_list[0]\n",
        "    try:\n",
        "        for idx in range(1, len(vec_list)):\n",
        "            vec_sum += vec_list[idx]\n",
        "    except:\n",
        "        print(vec_list)\n",
        "        exit()\n",
        "    return vec_sum.tolist()\n",
        "\n",
        "\n",
        "def mean_feature_sum(vec_list):\n",
        "    n = len(vec_list)\n",
        "    vec_list_sum = np.array(feature_sum(vec_list))\n",
        "    vec_list_sum = vec_list_sum/n\n",
        "    return vec_list_sum.tolist()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgCUWf6ai4YD"
      },
      "source": [
        "def get_svm_wordembds():\n",
        "\n",
        "    print('................ svm classifier.........')\n",
        "\n",
        "    model = svm.SVC(kernel='poly', random_state=123)\n",
        "    return model"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kVEc3CyirDx"
      },
      "source": [
        "def get_rfc_wordembds():\n",
        "\n",
        "    print('................ rfc classifier.........')\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=200, random_state=123)\n",
        "    return model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vppBNs8piuBC"
      },
      "source": [
        "def perform_classification_on_rawfeatures(X_train, y_train, X_test, y_test):\n",
        "\n",
        "    print('................ before clustering.........')\n",
        "\n",
        "    svc_model = get_svm_wordembds()\n",
        "    get_f1_score(X_train, y_train, X_test, y_test, svc_model)\n",
        "    rfc_model = get_rfc_wordembds()\n",
        "    get_f1_score(X_train, y_train, X_test, y_test, rfc_model)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GISxAXVah3ZH"
      },
      "source": [
        "def extract_feature_info_lstmdata(label_cnt, step_cnt, features, subject_activity_data):\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for idx in range(label_cnt):\n",
        "        class_label = subject_activity_data[idx*step_cnt][1]\n",
        "        y.append(class_label)\n",
        "\n",
        "        lower_lim = idx*step_cnt\n",
        "        upper_lim = ((idx+1)*step_cnt)\n",
        "        temp = []\n",
        "\n",
        "        for val in range(6):\n",
        "            temp.append(mean_feature_sum(features[val,lower_lim:upper_lim,:]))\n",
        "\n",
        "        X.append(mean_feature_sum(temp))\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9_crWl6oAZh"
      },
      "source": [
        "def perform_tuning_on_rawfeatures():\n",
        "\n",
        "  param_space_rfc = {\n",
        "          'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
        "          'max_depth': hp.choice('max_depth', [10, 15, 20, 25]),\n",
        "          'min_samples_split': hp.choice('min_samples_split', [2, 3, 4, 5]),\n",
        "          'min_samples_leaf': hp.choice('min_samples_leaf', [2, 3, 4, 5]),\n",
        "          'max_features': hp.choice('max_features', ['auto','sqrt', 10, 'log2']),\n",
        "          'bootstrap': hp.choice('bootstrap', ['True']),\n",
        "          'n_estimators': hp.choice('n_estimators', [100, 200, 400, 450, 500])\n",
        "          }\n",
        "\n",
        "  best_model_rfc = printbest_model(param_space_rfc)\n",
        "  return best_model_rfc  "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojf-WuKFhZ35"
      },
      "source": [
        "def perform_clf(features_train, features_test, subject_activity_data_train, subject_activity_data_test):\n",
        "\n",
        "    train_label_cnt = 7352\n",
        "    test_label_cnt = 2947\n",
        "    feature_dim = features_train.shape[2]\n",
        "    step_cnt = int(features_train.shape[1]/train_label_cnt)\n",
        "\n",
        "    X_train, y_train = extract_feature_info_lstmdata(train_label_cnt, step_cnt, features_train, subject_activity_data_train)\n",
        "    X_test, y_test = extract_feature_info_lstmdata(test_label_cnt, step_cnt, features_test, subject_activity_data_test)\n",
        "\n",
        "    X_train = np.array(X_train).reshape(-1,feature_dim).astype('float32')\n",
        "    y_train = np.array(y_train).astype('int32')\n",
        "    X_test = np.array(X_test).reshape(-1,feature_dim).astype('float32')\n",
        "    y_test = np.array(y_test).astype('int32')\n",
        "\n",
        "    perform_classification_on_rawfeatures(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeWYdPgMhCR8"
      },
      "source": [
        "subject_activity_data_train = np.loadtxt('/content/drive/MyDrive/lstm_data/activity_subject_data_train.csv', delimiter=',')\n",
        "sensor_features_train = np.loadtxt('/content/drive/MyDrive/lstm_data/UCIHAR_sensor_features_lstm_tuned_train.csv', delimiter=',')\n",
        "subject_activity_data_test = np.loadtxt('/content/drive/MyDrive/lstm_data/activity_subject_data_test.csv', delimiter=',')\n",
        "sensor_features_test = np.loadtxt('/content/drive/MyDrive/lstm_data/UCIHAR_sensor_features_lstm_tuned_test.csv', delimiter=',')\n",
        "\n",
        "train_channel_len = int(sensor_features_train.shape[0]/6)\n",
        "test_channel_len = int(sensor_features_test.shape[0]/6)\n",
        "feature_dim = sensor_features_train.shape[1]\n",
        "\n",
        "features_train = sensor_features_train.reshape(6, train_channel_len, feature_dim)\n",
        "features_test = sensor_features_test.reshape(6, test_channel_len, feature_dim)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT55oTxBwoN0",
        "outputId": "6fdc8dfe-56f8-4a22-8750-4941a8092e0a"
      },
      "source": [
        "X_train, y_train, X_test, y_test = perform_clf(features_train, features_test, subject_activity_data_train, subject_activity_data_test)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "................ before clustering.........\n",
            "................ svm classifier.........\n",
            "f1-score on features: 76.22457331645967 \n",
            "\n",
            "................ rfc classifier.........\n",
            "f1-score on features: 76.21558992862961 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdNktVUssx6O",
        "outputId": "e7c0f45f-5984-466d-a3b0-bddaa4c3959f"
      },
      "source": [
        "best_model_rfc = perform_tuning_on_rawfeatures()\n",
        "get_f1_score(X_train, y_train, X_test, y_test, best_model_rfc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzrMR9OQtmoJ"
      },
      "source": [
        "perform_classification_on_rawfeatures(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}