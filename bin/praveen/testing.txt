###################################### Testing #######################################

1) Applying Min-Max Normalization on every sensor channel for each subject.

{}: unused
1: Y1_D (9.74e-01) Y2_A (2.48e-02) X2_A (7.37e-04) Z2_A (6.51e-04) X1_A (2.12e-05) X2_B (8.39e-08) Z2_C (6.90e-08) Y2_C (4.85e-12) Y1_B (6.66e-21) Z1_B (1.68e-21)
2: Y1_B (3.75e-01) Y1_C (2.64e-01) X1_A (1.92e-01) X1_B (9.38e-02) Z1_B (4.03e-02) X1_C (3.22e-02) Z2_C (2.64e-03) Z1_A (5.27e-04) X2_B (3.44e-04) Y1_A (4.25e-05)
Words using topics: 0=0.0%, 1=1.2%, 2=98.8%

2) Applying Z-score Standardization on every sensor channel for each subject.

0: Y1_C (1.00e+00) Z1_A (3.69e-06) Z2_B (8.66e-17) Y1_A (5.97e-17) X2_C (3.57e-17) Y2_C (1.31e-17) X1_C (9.55e-18) Z1_B (3.63e-18) Y1_B (2.46e-18) X1_A (3.48e-20)
1: Y1_B (2.91e-01) Z1_B (2.76e-01) Z1_A (1.93e-01) X1_B (1.18e-01) Y1_A (8.04e-02) X1_C (3.21e-02) X1_A (9.32e-03) Z2_C (1.80e-14) Z2_B (6.13e-24) Y2_C (3.16e-33)
2: Z2_C (2.00e-01) X2_C (1.83e-01) X1_A (1.65e-01) X2_B (1.51e-01) Y2_B (1.31e-01) Z2_B (7.78e-02) Y1_B (4.97e-02) Z1_C (2.06e-02) Y2_C (1.27e-02) Z1_B (8.59e-03)
Words using topics: 0=0.1%, 1=93.4%, 2=6.5%

3) Without Normalization: window size 20 and 50% overlap

{}: unused
1: Z1_B (3.45e-01) X1_C (1.90e-01) Z1_A (1.73e-01) Y1_B (1.24e-01) Y1_A (1.09e-01) Y1_D (4.63e-02) X1_B (9.75e-03) X1_A (3.18e-03) Y2_B (7.13e-05) Z2_C (2.67e-06)
{}: unused
Words using topics: 0=0.0%, 1=100.0%, 2=0.0%

4) Without Normalization: window size 30 and 50% overlap

0: Z1_B (3.24e-01) Y1_C (2.21e-01) Z1_A (1.71e-01) X1_C (1.59e-01) Y1_A (5.75e-02) Y1_B (3.87e-02) X1_A (2.28e-02) X1_B (5.18e-03) Y2_B (4.10e-05) Z1_C (1.28e-06)
{}: unused
{}: unused
Words using topics: 0=100.0%, 1=0.0%, 2=0.0%

5) Without Normalization: window size 40 and 50% overlap

{}: unused
1: Z1_B (3.50e-01) Z1_A (2.20e-01) X1_A (1.57e-01) Y1_B (1.20e-01) X1_B (5.72e-02) Y1_C (5.48e-02) Y1_A (3.36e-02) X1_C (6.82e-03) Y2_C (3.37e-05) Z1_C (4.33e-08)
{}: unused
Words using topics: 0=0.0%, 1=100.0%, 2=0.0%

6) Without Normalization: window size 50 and 50% overlap

0: Z1_B (3.04e-01) Y1_A (2.31e-01) Z1_A (1.80e-01) X1_C (1.63e-01) X1_A (5.50e-02) Y1_B (4.65e-02) Y1_D (1.37e-02) X1_B (7.83e-03) Y2_C (1.03e-05) Z1_C (3.56e-08)
{}: unused
{}: unused
Words using topics: 0=100.0%, 1=0.0%, 2=0.0%

7) Considering 100 clusters for each subsequence(alpha=0.6, no.of instances=3000).

0: Z2_28 (1.75e-02) Y2_57 (1.65e-02) X2_3 (1.48e-02) Y2_56 (1.45e-02) X2_74 (1.24e-02) Y2_17 (1.24e-02) Y2_34 (1.24e-02) Z2_65 (1.21e-02) Y2_94 (1.18e-02) Z2_54 (1.08e-02)
1: Y1_21 (3.37e-02) Y2_13 (3.27e-02) Z2_38 (3.24e-02) Z2_28 (3.09e-02) Z2_10 (2.64e-02) Y2_62 (2.50e-02) Z2_89 (2.27e-02) X2_48 (2.27e-02) Y1_46 (2.21e-02) Y1_62 (2.19e-02)
2: Y1_62 (2.29e-01) Z2_13 (1.28e-01) Z2_0 (8.29e-02) Y1_46 (7.65e-02) Z2_66 (7.40e-02) Z1_22 (5.63e-02) Y2_47 (4.29e-02) Y2_17 (4.02e-02) Y2_13 (3.72e-02) Z2_26 (3.64e-02)
Words using topics: 0=0.3%, 1=5.1%, 2=94.7%

8) Considering 200 clusters for each subsequence(alpha=0.6, no.of instances=3000).

0: X2_61 (7.16e-02) Y1_39 (5.57e-02) X2_1 (4.67e-02) Y2_25 (4.56e-02) Z2_90 (4.29e-02) Y2_59 (3.98e-02) Z2_84 (3.83e-02) Z2_67 (3.39e-02) Y1_15 (3.31e-02) Y2_174 (2.64e-02)
1: Z2_168 (1.23e-02) Y1_39 (1.13e-02) Z2_62 (1.10e-02) X2_37 (1.08e-02) Y1_178 (1.04e-02) Z2_161 (1.03e-02) Y1_182 (9.24e-03) Y2_27 (9.19e-03) X2_61 (9.11e-03) Z2_125 (9.10e-03)
2: Y1_195 (3.31e-01) Z2_61 (1.90e-02) Z1_156 (1.71e-02) Z2_122 (1.70e-02) Y2_64 (1.60e-02) Y2_192 (1.46e-02) Z2_132 (1.44e-02) Y2_125 (1.39e-02) Z2_46 (1.39e-02) Y2_53 (1.36e-02)
Words using topics: 0=93.6%, 1=5.7%, 2=0.8%

9) Considering 300 clusters for each subsequence(alpha=0.6, no.of instances=3000).

0: Y2_254 (7.74e-02) X2_89 (5.64e-02) Z2_145 (5.09e-02) Z2_235 (4.16e-02) X2_180 (4.14e-02) Y1_16 (3.89e-02) Y2_164 (3.80e-02) Z2_87 (3.68e-02) Z2_45 (3.55e-02) X1_193 (3.54e-02)
1: Y1_171 (8.87e-03) Y1_16 (8.07e-03) Y1_128 (7.76e-03) Z2_242 (7.52e-03) Y2_254 (7.45e-03) Y1_79 (6.94e-03) Y2_232 (6.92e-03) Z2_129 (6.87e-03) Y2_103 (6.75e-03) Y2_238 (6.65e-03)
2: Y1_54 (8.49e-02) Z1_127 (1.50e-02) Y1_7 (6.42e-03) Y1_166 (6.17e-03) X1_93 (5.83e-03) X2_227 (5.59e-03) X1_54 (5.54e-03) Z1_146 (5.47e-03) Y1_91 (5.44e-03) Y2_172 (5.32e-03)
Words using topics: 0=95.3%, 1=4.0%, 2=0.7%


###################################### Approach 1.2 #######################################

1) Considering clustering statistics approach and performing glda on subject 101.

Words using topics: 0=0.0%, 1=0.1%, 2=0.0%, 3=95.7%, 4=1.7%, 5=0.0%, 6=0.2%, 7=2.2%